{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb28472-6bb4-4d14-8e01-d0f12a45590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uproot\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fbba86-bfd4-41b2-9b83-cf0199cbc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v01.06\"\n",
    "path = f\"/lfs/l1/legend/data/public/prodenv/prod-blind/ref/{version}/generated/tier/skm/phy/\"\n",
    "periods = os.listdir(path)\n",
    "\n",
    "df_r0 =pd.read_hdf(f'{path}p03/r000/l200-p03-r000-phy-%-tier_skm-taup23.ph5')\n",
    "df_r1 =pd.read_hdf(f'{path}p03/r001/l200-p03-r001-phy-%-tier_skm-taup23.ph5')\n",
    "df_r2 =pd.read_hdf(f'{path}p03/r002/l200-p03-r002-phy-%-tier_skm-taup23.ph5')\n",
    "df_r3 =pd.read_hdf(f'{path}p03/r003/l200-p03-r003-phy-%-tier_skm-taup23.ph5')\n",
    "df_r4 =pd.read_hdf(f'{path}p03/r004/l200-p03-r004-phy-%-tier_skm-taup23.ph5')\n",
    "df_r5 =pd.read_hdf(f'{path}p03/r005/l200-p03-r005-phy-%-tier_skm-taup23.ph5')\n",
    "df_4r0 =pd.read_hdf(f'{path}p04/r000/l200-p04-r000-phy-%-tier_skm-taup23.ph5')\n",
    "df_4r1 =pd.read_hdf(f'{path}p04/r001/l200-p04-r001-phy-%-tier_skm-taup23.ph5')\n",
    "df_4r2 =pd.read_hdf(f'{path}p04/r002/l200-p04-r002-phy-%-tier_skm-taup23.ph5')\n",
    "df_4r3 =pd.read_hdf(f'{path}p04/r003/l200-p04-r003-phy-%-tier_skm-taup23.ph5')\n",
    "\n",
    "df = pd.concat([df_r0, df_r1, df_r2, df_r3, df_r4, df_r5, df_4r0, df_4r1, df_4r2, df_4r3], verify_integrity=True)\n",
    "\n",
    "# load geds channelmap using legend_data_monitor\n",
    "import legend_data_monitor as ldm\n",
    "dataset = {\n",
    "    \"experiment\": \"L200\",\n",
    "    \"period\": \"p03\",\n",
    "    \"type\": \"phy\",\n",
    "    \"version\": \"\",\n",
    "    \"path\" : \"/lfs/l1/legend/data/public/prodenv/prod-blind/tmp/auto\", # MPIK cluster\n",
    "    \"runs\": 0,\n",
    "}\n",
    "geds = ldm.Subsystem(\"geds\", dataset=dataset)\n",
    "channel_map = geds.channel_map\n",
    "# giving same name so that merging the two dataframes is easier\n",
    "channel_map = channel_map.rename(columns = {\"channel\" : \"channel_id\"})\n",
    "# merge dataframes and add metadata information (detector name, string, position, etc.)\n",
    "df = df.merge(channel_map, on = \"channel_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af3a539-ce9d-4379-830c-0941bd3208a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df[(df.is_pulser == False) & (df.is_baseline == False) & (df.is_muon_tagged == False) & (df.is_physical == True) & (df.multiplicity == 1) & (df.is_valid_channel == True)]\n",
    "df_LArC = df[(df.is_pulser == False) & (df.is_baseline == False) & (df.is_muon_tagged == False) & (df.is_physical == True) & (df.multiplicity == 1) & (df.is_valid_channel == True) & (df.is_lar_rejected == True)]\n",
    "df_LArAC = df[(df.is_pulser == False) & (df.is_baseline == False) & (df.is_muon_tagged == False) & (df.is_physical == True) & (df.multiplicity == 1) & (df.is_valid_channel == True) & (df.is_lar_rejected == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779039e-91ab-424a-abb6-9f518f524e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_path_o25 = f\"/lfs/l1/legend/users/calgaro/taup/legend-gamma-lines-analysis/output/2023-08-21/0_25keV/raw\"\n",
    "C_path_o25 = f\"/lfs/l1/legend/users/calgaro/taup/legend-gamma-lines-analysis/output/2023-08-21/0_25keV/LArC\"\n",
    "AC_path_o25 = f\"/lfs/l1/legend/users/calgaro/taup/legend-gamma-lines-analysis/output/2023-08-21/0_25keV/LArAC\"\n",
    "\n",
    "exposure_path = f\"/lfs/l1/legend/users/calgaro/taup/legend-gamma-lines-analysis/livetime_and_exposure/exposure_in_kg_yr_on_p3_p4.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e497e-f97f-4ebb-92a3-6fb51d2f3371",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = ['K42_1525',\n",
    " 'K40_1461',\n",
    " 'Co60_1332',\n",
    " 'Co60_1173',\n",
    " 'Ac228_911',\n",
    " 'Bi212_727',\n",
    " 'Tl208_2614',\n",
    " 'Tl208_583',\n",
    " 'Tl208_861',\n",
    " 'Pa234m_1001',\n",
    " 'Pb214_352',\n",
    " 'Pb214_295',\n",
    " 'Bi214_609',\n",
    " 'Bi214_1378',\n",
    " 'Bi214_1764',\n",
    " 'Bi214_1238',\n",
    " 'Bi214_2204',\n",
    " 'Bi214_2448']\n",
    "min_x = [1505, 1441, 1313, 1153, 891, 707, 2595, 563, 841, 981, 332, 275, 589, 1358, 1744, 1218, 2184, 2428]\n",
    "max_x = [1545, 1481, 1353, 1193, 931, 747, 2635, 603, 881, 1021, 372, 315, 629, 1398, 1784, 1258, 2224, 2468]\n",
    "bkg = [\"step\", \"step\", \"linear\", \"linear\", \"linear\", \"linear\", \"flat\", \"linear\", \"linear\", \"linear\", \"quad\", \"quad\", \"linear\", \"linear\", \"linear\", \"linear\", \"flat\", \"flat\"]\n",
    "gammas_energies = [1524.7, 1460.8, 1332.5, 1173.2, 911.2, 727.3, 2614.5, 583.2, 860.6, 1001.0, 351.9, 295.2, 609.3, 1377.7, 1764.5, 1238.1, 2204.1, 2447.9]\n",
    "\n",
    "gammas_2 = [\"e+e-_Kr85_514\", \"Pb212_239_Pb214_242\", \"Ac228_338_Pb214_352\", \"Ac228_965_Ac228_969\", \"Bi214_1120_Zn65_1125\"]\n",
    "min_x_2 = [491, 218, 318, 945, 1100]\n",
    "max_x_2 = [534, 262, 372, 989, 1145]\n",
    "bkg_2 = [\"linear\", \"quad\", \"quad\", \"linear\", \"linear\"]\n",
    "gammas_energies_2 = [[511.0, 514.0], [238.6, 242.0], [338.3, 351.9], [964.8, 969.0], [1120.3, 1125.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3973d-378b-4004-81b2-fa09d7953b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p3 + p4\n",
    "ICPC_exposure = 8.0028 # kg yr\n",
    "BEGe_exposure = 2.0987 # kg yr\n",
    "\n",
    "dict_exposure = {\"ICPC\": ICPC_exposure, \"BEGe\": BEGe_exposure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ccc93c-7596-440d-9df2-856359666a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gamma     = []\n",
    "cut       = []\n",
    "det_type  = []\n",
    "intensity = []\n",
    "range_min = []\n",
    "range_max = []\n",
    "mean      = []\n",
    "mean_sigma= []\n",
    "fwhm      = []\n",
    "fwhm_sigma= []\n",
    "par0_0    = []\n",
    "par0_1    = []\n",
    "par1      = []\n",
    "par2      = []\n",
    "par0_0_sigma    = []\n",
    "par0_1_sigma    = []\n",
    "par1_sigma      = []\n",
    "par2_sigma      = []\n",
    "dict_exposure = {\"ICPC\": ICPC_exposure, \"BEGe\": BEGe_exposure}\n",
    "\n",
    "for cut_path in [RAW_path_o25, AC_path_o25, C_path_o25]:\n",
    "    for detector_type in [\"BEGe\", \"ICPC\"]:\n",
    "            with open(os.path.join(cut_path, detector_type, \"histo.gamma.log\")) as f:\n",
    "                f = f.readlines()\n",
    "            start_and_stop = [index for index, element in enumerate(f) if (\"*\" in element)]\n",
    "\n",
    "            for index in range(len(f)):\n",
    "                if (\"*\" in f[index]):\n",
    "                    if f[index].split(\" \")[1] not in gammas_2:\n",
    "                        gamma.append(f[index].split(\" \")[1])\n",
    "                        det_type.append(detector_type)\n",
    "                        if \"raw\"  in cut_path: cut.append(\"raw\")\n",
    "                        if \"LArAC\" in cut_path: cut.append(\"LArAC\")\n",
    "                        if \"LArC\" in cut_path: cut.append(\"LArC\")\n",
    "                        diff = 17 # default value\n",
    "                        if index in start_and_stop and index != 1:\n",
    "                            pos = start_and_stop.index(index)\n",
    "                            pos_minus_1 = pos-1\n",
    "                            diff = index - start_and_stop[pos_minus_1]\n",
    "\n",
    "                        for sub_index in range(diff):\n",
    "                            if \"intensity\" in f[index + sub_index]:\n",
    "                                try:\n",
    "                                    intensity.append(float(f[index + sub_index].split(\" \")[9][1:])/ dict_exposure[detector_type])\n",
    "                                    range_min.append(float(f[index + sub_index].split(\" \")[10].split(\",\")[0][1:])/ dict_exposure[detector_type]) \n",
    "                                    range_max.append(float(f[index + sub_index].split(\" \")[10].split(\",\")[1][:-2])/ dict_exposure[detector_type])\n",
    "                                except: \n",
    "                                    intensity.append(float(f[index+ sub_index].split(\" \")[10][1:])/ dict_exposure[detector_type]) \n",
    "                                    range_min.append(0.0)\n",
    "                                    range_max.append(0.0)\n",
    "                            if \"mean0\" in f[index + sub_index]:\n",
    "                                mean.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[0]))\n",
    "                                mean_sigma.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[1].split(\")\")[0])) \n",
    "                            if \"fwhm0\" in f[index + sub_index]:\n",
    "                                fwhm.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[0]))\n",
    "                                fwhm_sigma.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[1].split(\")\")[0]))\n",
    "                            if \"par0.0:\" in f[index + sub_index] and float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[0]) not in par0_0:\n",
    "                                par0_0.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[0]))\n",
    "                                par0_0_sigma.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[1].split(\")\")[0]))\n",
    "                            if \"par0.1:\" in f[index + sub_index]:\n",
    "                                par0_1.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[0]))\n",
    "                                par0_1_sigma.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[1].split(\")\")[0]))\n",
    "                            if \"par1:\" in f[index + sub_index]:\n",
    "                                par1.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[0]))\n",
    "                                par1_sigma.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[1].split(\")\")[0]))\n",
    "                            if \"par2:\" in f[index + sub_index]:\n",
    "                                par2.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[0]))\n",
    "                                par2_sigma.append(float(f[index + sub_index].split(\"(\")[1].split(\"+-\")[1].split(\")\")[0]))\n",
    "                if index in start_and_stop:\n",
    "                    # check length of bkg params\n",
    "                    if len(par0_0) < len(mean):\n",
    "                        par0_0.append(0)\n",
    "                        par0_0_sigma.append(0)\n",
    "                    if len(par0_1) < len(mean):\n",
    "                        par0_1.append(0)\n",
    "                        par0_1_sigma.append(0)\n",
    "                    if len(par1) < len(mean):\n",
    "                        par1.append(0)\n",
    "                        par1_sigma.append(0)\n",
    "                    if len(par2) < len(mean):\n",
    "                        par2.append(0)\n",
    "                        par2_sigma.append(0)\n",
    "                                \n",
    "df = pd.DataFrame()\n",
    "\n",
    "print(len(gamma))\n",
    "print(len(det_type))\n",
    "print(len(cut))\n",
    "print(len(intensity))\n",
    "print(len(range_min))\n",
    "print(len(range_max))\n",
    "print(len(mean), len(mean_sigma))\n",
    "print(len(fwhm), len(fwhm_sigma))\n",
    "print(len(par0_0), len(par0_0_sigma))\n",
    "print(len(par0_1), len(par0_1_sigma))\n",
    "print(len(par1), len(par1_sigma))\n",
    "print(len(par2), len(par2_sigma))\n",
    "\n",
    "df[\"gamma\"]     = gamma\n",
    "df[\"det_type\"]  = det_type\n",
    "df[\"cut\"]       = cut\n",
    "df[\"intensity\"] = intensity\n",
    "df[\"range_min\"] = range_min\n",
    "df[\"range_max\"] = range_max\n",
    "\"\"\"\n",
    "df[\"mean\"]      = mean\n",
    "df[\"mean_sigma\"]= mean_sigma\n",
    "df[\"fwhm\"]      = fwhm\n",
    "df[\"fwhm_sigma\"]= fwhm_sigma\n",
    "df[\"par0_0\"]      = par0_0\n",
    "df[\"par0_0_sigma\"]= par0_0_sigma\n",
    "df[\"par0_1\"]      = par0_1\n",
    "df[\"par0_1_sigma\"]= par0_1_sigma\n",
    "df[\"par1\"]        = par1\n",
    "df[\"par1_sigma\"]  = par1_sigma\n",
    "df[\"par2\"]        = par2\n",
    "df[\"par2_sigma\"]  = par2_sigma\n",
    "\"\"\"\n",
    "df\n",
    "\n",
    "df_2 = df.copy()\n",
    "df_2[\"yerr_low\"] = df_2.apply(lambda row: max(row[\"intensity\"] - row[\"range_min\"], 0), axis=1)\n",
    "df_2[\"yerr_upp\"] = df_2.apply(lambda row: max(-row[\"intensity\"] + row[\"range_max\"], 0), axis=1)\n",
    "df_2.loc[df_2[\"intensity\"] == df_2[\"yerr_low\"], \"yerr_low\"] = 0\n",
    "det_type_order = [\"BEGe\", \"ICPC\"]\n",
    "df_2['det_type'] = pd.Categorical(df_2['det_type'], categories=det_type_order, ordered=True)\n",
    "df_2 = df_2.sort_values(\"det_type\")\n",
    "df = df_2.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1249d7a-068c-45d5-95d3-7e70cdceebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_g = \"Co60_1332\"\n",
    "my_cut = \"LArC\"\n",
    "df[(df.gamma==my_g) & (df.cut==my_cut)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca9a59-e4e2-45ec-9e43-07bd66bf0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = df[(df.gamma==my_g) & (df.cut==my_cut)].copy()\n",
    "bege = df_avg[(df_avg.det_type==\"BEGe\")][\"intensity\"].iloc[0]\n",
    "icpc = df_avg[(df_avg.det_type==\"ICPC\")][\"intensity\"].iloc[0]\n",
    "bege_low = df_avg[(df_avg.det_type==\"BEGe\")][\"yerr_low\"].iloc[0]\n",
    "icpc_low = df_avg[(df_avg.det_type==\"ICPC\")][\"yerr_low\"].iloc[0]\n",
    "bege_upp = df_avg[(df_avg.det_type==\"BEGe\")][\"yerr_upp\"].iloc[0]\n",
    "icpc_upp = df_avg[(df_avg.det_type==\"ICPC\")][\"yerr_upp\"].iloc[0]\n",
    "print( (bege*dict_exposure[\"BEGe\"] + icpc*dict_exposure[\"ICPC\"])/(dict_exposure[\"BEGe\"]+dict_exposure[\"ICPC\"]))\n",
    "print( (bege_low*dict_exposure[\"BEGe\"] + icpc_low*dict_exposure[\"ICPC\"])/(dict_exposure[\"BEGe\"]+dict_exposure[\"ICPC\"]))\n",
    "print( (bege_upp*dict_exposure[\"BEGe\"] + icpc_upp*dict_exposure[\"ICPC\"])/(dict_exposure[\"BEGe\"]+dict_exposure[\"ICPC\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ab5b4-1f7b-4472-bf37-0f0a233d449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_width = 0.25  # leave this for visualization reasons (but remember the final fit considers a bin widht of 0.25 keV)\n",
    "min_energy = 0\n",
    "max_energy = 5000\n",
    "num_bins = int((max_energy - min_energy) / bin_width)\n",
    "\n",
    "x_fit = np.linspace(0, 5000, 50000)\n",
    "\n",
    "def step_function(x, centroid, low_value, upp_value):\n",
    "    return np.where(x >= centroid, upp_value, low_value)\n",
    "\n",
    "def gaussian(x, intensity, mu, sigma):\n",
    "    # from BAT:\n",
    "    #    par[2]/sqrt(2*TMath::Pi()*pow(par[1]/2.35,2))*exp(-0.5*pow(x[0]-par[0],2)/pow(par[1]/2.35,2));\n",
    "    return (intensity / (np.sqrt(2*np.pi)*sigma)) * np.exp(-0.5 * (((x - mu) / sigma)**2))\n",
    "    #return (intensity / ((2*np.pi)*sigma*sigma)) * np.exp(-0.5 * (((x - mu) / sigma)**2))\n",
    "    \n",
    "def fit_flat(a):\n",
    "    return a\n",
    "def fit_linear(x, off, a, b):\n",
    "    return a + b*(x-off)\n",
    "def fit_quad(x, off, a, b,c):\n",
    "    return a + b*(x-off) + c*(x-off)**2\n",
    "\n",
    "\n",
    "color_cut = {\"raw\" : \"#07A9FF\", \"LArAC\": \"red\", \"LArC\" : \"orange\"}\n",
    "legend_dict = {\"raw\" : \"prior LAr veto\", \"LArAC\": \"after LAr veto\", \"LArC\" : \"coincident with LAr veto\"}\n",
    "#dict_exposure = {\"ICPC\": ICPC_exposure, \"BEGe\": BEGe_exposure}\n",
    "dict_exposure = {\"ICPC\": 1, \"BEGe\": 1}\n",
    "\n",
    "for idx_g,g in enumerate(gammas):\n",
    "    if \"911\" not in g and \"352\" not in g:\n",
    "        continue\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))  \n",
    "    \n",
    "    for idx,det in enumerate([\"BEGe\", \"ICPC\"]):\n",
    "        df_data = df.copy()\n",
    "        df_raw_det = df_raw.copy()\n",
    "        df_LArC_det = df_LArC.copy()\n",
    "        df_LArAC_det = df_LArAC.copy()\n",
    "        \n",
    "        # select data coming from one detector type only\n",
    "        if det == \"BEGe\":\n",
    "            df_raw_det = df_raw_det[df_raw_det['name'].str.startswith('B')]\n",
    "            df_LArC_det = df_LArC_det[df_LArC_det['name'].str.startswith('B')]\n",
    "            df_LArAC_det = df_LArAC_det[df_LArAC_det['name'].str.startswith('B')]\n",
    "        if det == \"ICPC\":\n",
    "            df_raw_det = df_raw_det[df_raw_det['name'].str.startswith('V')]\n",
    "            df_LArC_det = df_LArC_det[df_LArC_det['name'].str.startswith('V')]\n",
    "            df_LArAC_det = df_LArAC_det[df_LArAC_det['name'].str.startswith('V')]\n",
    "\n",
    "        # get energies of interest\n",
    "        df_raw_det = df_raw_det[(df_raw_det[\"energy\"] >= min_x[idx_g]) & (df_raw_det[\"energy\"] <= max_x[idx_g])]\n",
    "        df_LArC_det = df_LArC_det[(df_LArC_det[\"energy\"] >= min_x[idx_g]) & (df_LArC_det[\"energy\"] <= max_x[idx_g])]\n",
    "        df_LArAC_det = df_LArAC_det[(df_LArAC_det[\"energy\"] >= min_x[idx_g]) & (df_LArAC_det[\"energy\"] <= max_x[idx_g])]\n",
    "        \n",
    "          \n",
    "        # ------------------------------------------------------------------------------------------------------------\n",
    "        # start plot\n",
    "        ax = axes[idx]  \n",
    "\n",
    "        # RAW DATA\n",
    "        hist_values_raw, bin_edges_raw = np.histogram(df_raw_det['energy'], bins=num_bins, range=(min_energy, max_energy))\n",
    "        bin_midpoints_raw = (bin_edges_raw[:-1] + bin_edges_raw[1:]) / 2\n",
    "        #if det == \"BEGe\":\n",
    "        #    ax.scatter(bin_midpoints_raw, hist_values_raw / dict_exposure[det], marker='.', color=color_cut[\"raw\"], label=legend_dict[\"raw\"])\n",
    "        #else:\n",
    "        #    ax.scatter(bin_midpoints_raw, hist_values_raw / dict_exposure[det], marker='.', color=color_cut[\"raw\"])\n",
    "        \n",
    "        # LArAC DATA\n",
    "        hist_values_LArAC, bin_edges_LArAC = np.histogram(df_LArAC_det['energy'], bins=num_bins, range=(min_energy, max_energy))\n",
    "        bin_midpoints_LArAC = (bin_edges_LArAC[:-1] + bin_edges_LArAC[1:]) / 2\n",
    "        if det == \"BEGe\":\n",
    "            ax.scatter(bin_midpoints_LArAC, hist_values_LArAC / dict_exposure[det], marker='.', color=color_cut[\"LArAC\"], label=legend_dict[\"LArAC\"])\n",
    "        else:\n",
    "            ax.scatter(bin_midpoints_LArAC, hist_values_LArAC / dict_exposure[det], marker='.', color=color_cut[\"LArAC\"])\n",
    "        \n",
    "        \n",
    "        # LArC DATA\n",
    "        hist_values_LArC, bin_edges_LArC = np.histogram(df_LArC_det['energy'], bins=num_bins, range=(min_energy, max_energy))\n",
    "        bin_midpoints_LArC = (bin_edges_LArC[:-1] + bin_edges_LArC[1:]) / 2\n",
    "        #if det == \"BEGe\":\n",
    "        #    ax.scatter(bin_midpoints_LArC, hist_values_LArC / dict_exposure[det], marker='.', color=color_cut[\"LArC\"], label=legend_dict[\"LArC\"])\n",
    "        #else:\n",
    "        #    ax.scatter(bin_midpoints_LArC, hist_values_LArC / dict_exposure[det], marker='.', color=color_cut[\"LArC\"])\n",
    "        \n",
    "        # Generate the best-fit curve\n",
    "        for my_cut in [\"LArAC\"]:#\"raw\", \"LArAC\", \"LArC\"]:\n",
    "            centroid = gammas_energies[idx_g]\n",
    "            offset = min_x[idx_g] # there is an offest set to range.first in BAT code\n",
    "            print(offset)\n",
    "            condition = (df_data.gamma == g) & (df_data.cut == my_cut) & (df_data.det_type == det)\n",
    "            df_data = df_data.copy()[condition]\n",
    "            intensity = df_data[\"intensity\"].iloc[0] \n",
    "            intensity_sigma_upp = df_data[\"yerr_upp\"].iloc[0]\n",
    "            intensity_sigma_low = df_data[\"yerr_low\"].iloc[0] \n",
    "            mean      = df_data[\"mean\"].iloc[0]\n",
    "            stddev    = df_data[\"fwhm\"].iloc[0] / 2.355\n",
    "            fwhm      = df_data[\"fwhm\"].iloc[0] \n",
    "            mean_sigma = df_data[\"mean_sigma\"].iloc[0]\n",
    "            stddev_sigma = df_data[\"fwhm_sigma\"].iloc[0] / 2.355\n",
    "            fwhm_sigma   = df_data[\"fwhm_sigma\"].iloc[0] \n",
    "            # gaussian signal\n",
    "            if det==\"BEGe\":\n",
    "                print(my_cut, intensity, intensity_sigma_low, intensity_sigma_upp, mean, stddev, fwhm)\n",
    "            \n",
    "            y_fit = gaussian(x_fit, intensity, mean, stddev)  * bin_width\n",
    "            y_fit_lower = gaussian(x_fit, intensity, mean, stddev)  * bin_width\n",
    "            y_fit_upper = gaussian(x_fit, intensity, mean, stddev)  * bin_width\n",
    "            #y_fit_lower = gaussian(x_fit, intensity-intensity_sigma_low, mean-mean_sigma, stddev-stddev_sigma) * bin_width\n",
    "            #y_fit_upper = gaussian(x_fit, intensity+intensity_sigma_upp, mean+mean_sigma, stddev+stddev_sigma) * bin_width\n",
    "            \n",
    "            # add background\n",
    "            if bkg[idx_g] == \"step\":\n",
    "                if df_data[\"par0_0\"].iloc[0]!=0 and df_data[\"par0_1\"].iloc[0]!=0:\n",
    "                    if det==\"BEGe\":\n",
    "                        print(\"par0_0\", df_data[\"par0_0\"].iloc[0], \"par0_1\", df_data[\"par0_1\"].iloc[0])\n",
    "                        print(\"par0_0_sigma\", df_data[\"par0_0_sigma\"].iloc[0], \"par0_1_sigma\", df_data[\"par0_1_sigma\"].iloc[0])\n",
    "                    \n",
    "                    a = df_data[\"par0_0\"].iloc[0] * bin_width\n",
    "                    a_std = df_data[\"par0_0_sigma\"].iloc[0] * bin_width\n",
    "                    b = df_data[\"par0_1\"].iloc[0] * bin_width\n",
    "                    b_std = df_data[\"par0_1_sigma\"].iloc[0] * bin_width\n",
    "                    y_fit += step_function((x_fit-offset), centroid, a, b)\n",
    "                    y_fit_lower += step_function((x_fit-offset), centroid, a-a_std, b-b_std)\n",
    "                    y_fit_upper += step_function((x_fit-offset), centroid, a+a_std, b+b_std)\n",
    "            if bkg[idx_g] == \"flat\":\n",
    "                if df_data[\"par0_0\"].iloc[0]!=0:\n",
    "                    if det==\"BEGe\":\n",
    "                        print(\"par0_0\", df_data[\"par0_0\"].iloc[0])\n",
    "                        print(\"par0_0_sigma\", df_data[\"par0_0_sigma\"].iloc[0])\n",
    "                    \n",
    "                    a = df_data[\"par0_0\"].iloc[0] * bin_width\n",
    "                    a_std = df_data[\"par0_0_sigma\"].iloc[0] * bin_width\n",
    "                    y_fit += fit_flat(a)\n",
    "                    y_fit_lower += fit_flat(a-a_std)\n",
    "                    y_fit_upper += fit_flat(a+a_std)\n",
    "            if bkg[idx_g] == \"linear\":\n",
    "                if df_data[\"par0_0\"].iloc[0]!=0 and df_data[\"par1\"].iloc[0]!=0:\n",
    "                    if det==\"BEGe\":\n",
    "                        print(\"par0_0\", df_data[\"par0_0\"].iloc[0], \"par1\", df_data[\"par1\"].iloc[0])\n",
    "                        print(\"par0_0_sigma\", df_data[\"par0_0_sigma\"].iloc[0], \"par1_sigma\", df_data[\"par1_sigma\"].iloc[0])\n",
    "                    \n",
    "                    a = df_data[\"par0_0\"].iloc[0] * bin_width\n",
    "                    a_std = df_data[\"par0_0_sigma\"].iloc[0] * bin_width\n",
    "                    b = df_data[\"par1\"].iloc[0] * bin_width\n",
    "                    b_std = df_data[\"par1_sigma\"].iloc[0] * bin_width\n",
    "                    y_fit += fit_linear(x_fit, offset, a, b)\n",
    "                    y_fit_lower += fit_linear(x_fit, offset, a-a_std, b-b_std)\n",
    "                    y_fit_upper += fit_linear(x_fit, offset, a+a_std, b+b_std)\n",
    "            if bkg[idx_g] == \"quad\":\n",
    "                if df_data[\"par0_0\"].iloc[0]!=0 and df_data[\"par1\"].iloc[0]!=0 and df_data[\"par2\"].iloc[0]!=0:\n",
    "                    a = df_data[\"par0_0\"].iloc[0] * bin_width\n",
    "                    a_std = df_data[\"par0_0_sigma\"].iloc[0] * bin_width\n",
    "                    b = df_data[\"par1\"].iloc[0] * bin_width\n",
    "                    b_std = df_data[\"par1_sigma\"].iloc[0] * bin_width\n",
    "                    c = df_data[\"par2\"].iloc[0] * bin_width\n",
    "                    c_std = df_data[\"par2_sigma\"].iloc[0] * bin_width\n",
    "                    if det==\"BEGe\":\n",
    "                        print(\"par0_0\", a, \"par1\", b, \"par2\", c)\n",
    "                        print(\"par0_0_sigma\", a_std, \"par1_sigma\", b_std, \"par2_sigma\", c_std)\n",
    "                    y_fit += fit_quad(x_fit, offset, a, b, c)\n",
    "                    y_fit_lower += fit_quad(x_fit, offset, a-a_std, b-b_std, c-c_std)\n",
    "                    y_fit_upper += fit_quad(x_fit, offset, a+a_std, b+b_std, c+c_std)\n",
    "            \n",
    "            # plot\n",
    "            ax.plot(x_fit, y_fit / dict_exposure[det], color=color_cut[my_cut])\n",
    "            ax.fill_between(x_fit, y_fit_lower / dict_exposure[det], y_fit_upper / dict_exposure[det], color=color_cut[my_cut], alpha=0.2)\n",
    "\n",
    "            # some plotting styles\n",
    "            energy_values_raw = hist_values_raw / dict_exposure[det]\n",
    "            energy_values_LArC = hist_values_LArC / dict_exposure[det]\n",
    "            energy_values_LArAC = hist_values_LArAC / dict_exposure[det]\n",
    "            ymax_energy = max(energy_values_raw.max(), energy_values_LArC.max(), energy_values_LArAC.max(), 5)\n",
    "            ax.set_ylim(-1, 5)#ymax_energy)\n",
    "            ax.set_xlim(min_x[idx_g], max_x[idx_g])\n",
    "            import matplotlib.ticker as ticker\n",
    "            ax.yaxis.set_major_locator(ticker.MaxNLocator(30))\n",
    "            ax.set_xlabel('Energy (keV)')\n",
    "            if dict_exposure[det]==1:\n",
    "                ax.set_ylabel(f'Rate [cts/{bin_width}keV]')\n",
    "            else:\n",
    "                ax.set_ylabel(f'Rate [cts/(kg yr {bin_width}keV)]')\n",
    "            ax.text(0.95, 0.95, det+f\"\\n{round(dict_exposure[det],3)} kg yr\", transform=ax.transAxes, va=\"top\", ha=\"right\")\n",
    "        \n",
    "    fig.suptitle(f\"Line: {g}\")\n",
    "    fig.legend(loc='upper right', bbox_to_anchor=(1.18, 0.55))\n",
    "    plt.tight_layout() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730021ac-417f-4b18-8c48-bc6198718bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated example data\n",
    "x_data = np.linspace(1000, 2000, 100)\n",
    "y_data = 0.00529 * (x_data - 1313) + 1.26908 + np.random.normal(0, 0.1, len(x_data))  # Simulated noisy data\n",
    "\n",
    "# Define the quadratic function\n",
    "def quadratic_function(x, a, b, c):\n",
    "    return a + b * x + c * x**2\n",
    "\n",
    "# Example best-fit parameters\n",
    "best_fit_params = [1.26908, 0.00529, 0.0]  # Example best-fit parameters [a, b, c]\n",
    "\n",
    "# Example parameter uncertainties (standard deviations)\n",
    "param_uncertainties = [0.02, 0.0001, 0.0002]  # Example uncertainties [std_a, std_b, std_c]\n",
    "\n",
    "# Generate x values for plotting\n",
    "x_fit_values = np.linspace(1000, 2000, 100)\n",
    "\n",
    "# Calculate the fitted function values using best-fit parameters\n",
    "fitted_values = quadratic_function(x_fit_values, *best_fit_params)\n",
    "\n",
    "# Calculate upper and lower bounds of the 68% credible interval\n",
    "upper_bound = quadratic_function(x_fit_values, *np.array(best_fit_params) + param_uncertainties)\n",
    "lower_bound = quadratic_function(x_fit_values, *np.array(best_fit_params) - param_uncertainties)\n",
    "\n",
    "# Plot the data, fitted function, and 68% credible interval\n",
    "plt.plot(x_data, y_data, 'o', label='Data')\n",
    "plt.plot(x_fit_values, fitted_values, label='Fitted Quadratic Function')\n",
    "plt.fill_between(x_fit_values, lower_bound, upper_bound, color='gray', alpha=0.3, label='68% Credible Interval')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Quadratic Fit Result with 68% Credible Interval')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb56a6bb-03d9-4908-b978-4e6c066fb7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(x_fit, step_function(x_fit, 1524.7, 0.423, 0.382)+gaussian(x_fit, 53.9/(np.sqrt(2)*0.83), 1525, 0.83), color='g')\n",
    "x = np.linspace(1313,1353,40)\n",
    "plt.plot(x, 0.00529*(x-1353) + 1.26908) # 0.25 , Co60 @ 1332\n",
    "plt.xlim(1313, 1353)\n",
    "num_ticks = 10  # Number of ticks you want\n",
    "plt.yticks(np.linspace((1.0), (1.5), num_ticks))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2faac7-ccf0-4bfb-a827-fb2eb351929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated data points\n",
    "x_data = np.linspace(0, 10, 20)\n",
    "y_data = 2 * x_data + 1 + np.random.normal(0, 0.5, len(x_data))\n",
    "\n",
    "# Fit results (these should be extracted from your BAT fit)\n",
    "best_fit_slope = 2.0\n",
    "best_fit_intercept = 1.0\n",
    "slope_uncertainty = 0.1\n",
    "intercept_uncertainty = 0.2\n",
    "\n",
    "# Generate the best-fit curve\n",
    "x_fit = np.linspace(0, 10, 100)\n",
    "y_fit = best_fit_slope * x_fit + best_fit_intercept\n",
    "\n",
    "# Generate the uncertainty band\n",
    "y_fit_upper = (best_fit_slope + slope_uncertainty) * x_fit + (best_fit_intercept + intercept_uncertainty)\n",
    "y_fit_lower = (best_fit_slope - slope_uncertainty) * x_fit + (best_fit_intercept - intercept_uncertainty)\n",
    "\n",
    "# Plot the data, best-fit result, and uncertainty band\n",
    "plt.figure()\n",
    "plt.errorbar(x_data, y_data, yerr=0.5, fmt=\"o\", label=\"Data\")\n",
    "plt.plot(x_fit, y_fit, label=\"Best-Fit Curve\", color=\"red\")\n",
    "plt.fill_between(x_fit, y_fit_lower, y_fit_upper, color=\"red\", alpha=0.2, label=\"68% Credible Interval\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.title(\"Fit Results with Uncertainty Band\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
